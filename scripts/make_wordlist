#!/usr/bin/python3
#
# Copyright (c) 2020 Jeff Doozan
#
# This is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

"""
This will build a dictionary from an english wiktionary dump
"""

import os
import re
import sys
import multiprocessing

os.environ["PYWIKIBOT_NO_USER_CONFIG"]="2"
from pywikibot import xmlreader

from enwiktionary_parser.languages.all_ids import ALL_LANG_IDS

from enwiktionary_wordlist.wikiextract import WikiExtractWithRev
from enwiktionary_wordlist.utils import make_language_pattern
from enwiktionary_wordlist.wordlist import Wordlist
from enwiktionary_wordlist.wordlist_builder import WordlistBuilder

import enwiktionary_templates
cachedb = enwiktionary_templates.cache.get_default_cachedb()

def iter_langdata(datafile):

    if not os.path.isfile(datafile):
        raise FileNotFoundError(f"Cannot open: {datafile}")

    return WikiExtractWithRev.iter_articles_from_bz2(datafile)

def iter_xml(datafile, lang_section):

    if not os.path.isfile(datafile):
        raise FileNotFoundError(f"Cannot open: {datafile}")

    dump = xmlreader.XmlDump(datafile)
    parser = dump.parse()

    pattern = make_language_pattern(lang_section)

    for entry in parser:

        if ":" in entry.title or "/" in entry.title:
            continue

        match = re.match(pattern, entry.text)
        if not match:
            continue

        lang_entry = match.group(0)

        yield entry.title, lang_entry, entry.revisionid


_builder = None
def make_entry(item):
    title, entry, revision = item

    entry = _builder.entry_to_text(entry, title)
    if entry:
        return title, entry

def main():
    import argparse
    global _builder

    parser = argparse.ArgumentParser(description="Convert *nym sections to tags.")
    parser.add_argument("--xml", help="Read entries from specified wiktionary XML dump")
    parser.add_argument("--langdata", help="Read articles from specified language data file")
    parser.add_argument("--wordlist", help="Read articles from existing wordlist")
    parser.add_argument("--lang-id", help="Language id")
    parser.add_argument("--transcludes", help="Senses that can be transcluded by {{transclude sense}}")
    parser.add_argument("-j", help="run N jobs in parallel (default = # CPUs - 1", type=int)
    parser.add_argument("--limit", help="Limit to n entries", type=int, default=0)
    parser.add_argument('--progress', action='store_true')
    parser.add_argument('--exclude-verb-forms', action='store_true', help="Exclude all verb forms")
    parser.add_argument('--exclude-generated-forms', action='store_true', help="Exclude forms entries that can be generate automatically")
    parser.add_argument('--exclude-empty', action='store_true', help="Exclude words with no senses")
    parser.add_argument('--expand-templates', action='store_true', help="Convert templates to text")

    args = parser.parse_args()

    if not args.j:
        args.j = multiprocessing.cpu_count()-1

    count = 0
    entries = {}

    if args.langdata or args.xml:
        if not args.lang_id:
            raise ValueError("--lang-id is required when using --xml or --langdata")

        elif args.lang_id not in ALL_LANG_IDS:
            raise ValueError(f"Unknown language id: {args.lang_id}")

        lang_section = ALL_LANG_IDS[args.lang_id]
        _builder = WordlistBuilder(lang_section, args.lang_id, args.transcludes, args.expand_templates)

        if args.langdata:
            iter_entry = iter_langdata(args.langdata)
        else:
            iter_entry = iter_xml(args.xml, lang_section)

        wordlist = Wordlist(template_cachedb=cachedb)
        count = 0

        if args.j > 1:
            pool = multiprocessing.Pool(args.j)
            iter_items =  pool.imap_unordered(make_entry, iter_entry, 100)
        else:
            iter_items = map(make_entry, iter_entry)

        for item in iter_items:
            if not item:
                continue
            title, entry = item

            count += 1

            if count % 10 == 0 and args.progress:
                print(count, file=sys.stderr, end="\r")
            if args.limit and count >= args.limit:
                break
            wordlist.all_entries[title] = map(str.lstrip, entry)

    elif args.wordlist:
        wordlist = Wordlist(template_cachedb=cachedb)
        with open(args.wordlist) as infile:
            for title, entry in Wordlist._iter_entries(infile):
                count += 1
                if count % 1000 == 0 and args.progress:
                    print(count, file=sys.stderr, end="\r")
                if args.limit and count >= args.limit:
                    break
                wordlist.all_entries[title] = map(str.lstrip, entry)

    else:
        raise ValueError("No input file specified, use --xml or --lang-data or --wordlist")

    for entry in WordlistBuilder.from_wordlist(wordlist, exclude_generated=args.exclude_generated_forms, exclude_empty=args.exclude_empty):
        print(entry)

    print(count, "entries processed", file=sys.stderr)

if __name__ == "__main__":
    main()

